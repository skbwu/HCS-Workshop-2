{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HCS Workshop 2, Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Skyler Wu (based on Will Cooper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "b'<!DOCTYPE html>\\n<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <p>Here is some simple content for this page.</p>\\n    </body>\\n</html>'\n"
     ]
    }
   ],
   "source": [
    "# import requests package and set up page\n",
    "# https://dataquestio.github.io/web-scraping-pages/simple.html\n",
    "\n",
    "import requests\n",
    "\n",
    "page = requests.get(\"https://dataquestio.github.io/web-scraping-pages/simple.html\")\n",
    "# print status code (200 = \"success\". 404 = error, etc.)\n",
    "print(page.status_code)\n",
    "# prints the actual HTML that's in the page. the exact same thing as the inspect element stuff.\n",
    "print(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   A simple example page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p>\n",
      "   Here is some simple content for this page.\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# import BeautifulSoup and make a \"BeautifulSoup object\"\n",
    "# sudo apt-get install python-bs4\n",
    "\n",
    "# How to import:\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "# standard = store all page content as variable called \"soup\"\n",
    "# 'html.parser' because we know that it's written in html. also xml stuff. html.parser covers most stuff.\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# makes the html code look a lot easier to read.\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head\n",
      "<p>Here is some simple content for this page.</p>\n"
     ]
    }
   ],
   "source": [
    "# list soup children, title, etc.\n",
    "# children of the soup. list command converts stuff to a list.\n",
    "list(soup.children)\n",
    "list(soup.title) # gives exactly what is in between the title tags.\n",
    "\n",
    "# note tags can be nested!\n",
    "print(soup.title.parent.name)\n",
    "\n",
    "# returns the paragraph tag.\n",
    "print(soup.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here is some simple content for this page.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more printing\n",
    "\n",
    "# listing the children makes more comma separation.\n",
    "html = list(soup.children)[2]\n",
    "list(html.children)\n",
    "\n",
    "body = list(html.children)[3] #4th element of the children list\n",
    "list(body.children) # lists body's children.\n",
    "p = list(body.children)[1] \n",
    "list(p.children) #how to narrow it down to some text that you want to find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find function - returns very first thing it finds with the tag that you indicates\n",
    "# or if use find-all, returns all instances of the tag you're looking for.\n",
    "\n",
    "soup.find('p').get_text() # to get rid of the tags on first instance found,\n",
    "soup.findAll('p') # finds ALL paragraph tags. returns as list. CANNOT use get_text()!\n",
    "\n",
    "soup.find('head').get_text() # still pretty much returns the text that was in the head tags.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"tombstone-container\">\n",
      " <p class=\"period-name\">\n",
      "  NOW: Multiple\n",
      "  <br/>\n",
      "  hazards in effect\n",
      " </p>\n",
      " <p>\n",
      "  <img alt=\"\" class=\"forecast-icon\" src=\"newimages/medium/nfew.png\" title=\"\"/>\n",
      " </p>\n",
      " <p class=\"short-desc\">\n",
      "  Click HERE for Details\n",
      " </p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "# Example: weather\n",
    "\n",
    "# URL to a weather website. plugged in longitude and latitude.\n",
    "page = requests.get(\"http://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168\")\n",
    "\n",
    "# set soup variable with BeautifulSoup class.\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# set \"id\" to a string that we want. \"id\" is one of the arguments that you can put into a tag.\n",
    "# check inspect element to find specifics.\n",
    "seven_day = soup.find(id = 'seven-day-forecast')\n",
    "\n",
    "# you have to inspect element to find \"tombstone-container\"\n",
    "# not intuitive.\n",
    "# \"class\" itself is a keyword in python, so we have to use \"class_\"\n",
    "forecast_items = seven_day.find_all(class_ = 'tombstone-container')\n",
    "tonight = forecast_items[0]\n",
    "print(tonight.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOW: Multiplehazards in effect\n",
      "Click HERE for Details\n"
     ]
    }
   ],
   "source": [
    "period = tonight.find(class_=\"period-name\").get_text()\n",
    "short_desc = tonight.find(class_=\"short-desc\").get_text()\n",
    "#temp = tonight.find(class_=\"temp\").get_text()\n",
    "print(period)\n",
    "print(short_desc)\n",
    "#print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more sources?\n",
    "# https://beautiful-soup-4.readthedocs.io/en/Latest/\n",
    "# https://www.dataquest.io/blog/web-scraping-tutorial-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# 'https://markets.businessinsider.com/stocks'\n",
    "page = requests.get('https://markets.businessinsider.com/stocks')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# can hover lines of HTML code in inspect element until I find the element that I want.\n",
    "# look for the relevant classnames. should have a special ID.\n",
    "\n",
    "stocks = soup.find(id = 'shares_topflop_StockPricesSharesTopFlop')\n",
    "asdf = stocks.find('a') # would return the first row of the table. based on inspect element.\n",
    "\n",
    "#in html, you have a \"table\" class, and then \"tr\" means \"table row\"\n",
    "prices = stocks.find_all(class_='row-hover')\n",
    "# ^ this still looks ugly.\n",
    "\n",
    "names = []\n",
    "for i in range(len(prices)):\n",
    "        names.append(prices[i].find('a').get_text())\n",
    "\n",
    "print(names)\n",
    "# for price in prices: # actually prints all of the stocks!\n",
    "        # print(price.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# regular expressions, searching by text\n",
    "# https://docs.python.org/3/library/re.html\n",
    "\n",
    "import re\n",
    "\n",
    "bruh = stocks.find_all('a', text = re.compile(\"Apple\"))\n",
    "print(bruh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/47928608/how-to-use-beautifulsoup-to-parse-google-search-results-in-python\n",
    "# quick example of using BeautifulSoup to Google for you\n",
    "\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import webbrowser\n",
    "\n",
    "# create text variable.\n",
    "text = \"hello-world\"\n",
    "text = urllib.parse.quote_plus(text)\n",
    "\n",
    "#concatenating strings together because that's the format of a google search query.\n",
    "url = 'https://google.com/search?q=' + text\n",
    "\n",
    "# requests library gets our url.\n",
    "response = requests.get(url)\n",
    "\n",
    "# this will open another tab in our browser that has the output in it.\n",
    "with open('output.html', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "webbrowser.open('output.html')\n",
    "\n",
    "# use beautiful soup to parse the html stuff that Google returned in plain text form.\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "for g in soup.find_all(class_=\"Bneaweajwlf\"):\n",
    "    print(g.get_text())\n",
    "    print('---')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Time:\n",
    "# find any website you want to do some scraping.\n",
    "# write a python script to nicely print out interesting information on the page.\n",
    "# That's it!\n",
    "\n",
    "# requirements are kind of light!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
